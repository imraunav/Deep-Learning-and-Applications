{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import(data_path):\n",
    "    class_labels = os.listdir(data_path) # reads directory names as class-labels\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    for class_ in class_labels:\n",
    "        if class_ == '.DS_Store':\n",
    "            continue\n",
    "        class_path = data_path+'/'+class_\n",
    "        imgs = os.listdir(class_path) # reads images names to read\n",
    "        for img in imgs:\n",
    "            if img == '.DS_Store':\n",
    "                continue\n",
    "            data.append(cv2.imread(class_path+'/'+img, cv2.IMREAD_GRAYSCALE))\n",
    "            labels.append(int(class_))\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of data\n",
      "No. of train images: 11385\n",
      "No. of test images: 3795\n",
      "No. of val images: 3795\n"
     ]
    }
   ],
   "source": [
    "test_path='./Group_10/test'\n",
    "train_path='./Group_10/train'\n",
    "val_path='./Group_10/val'\n",
    "# test_data, test_labels = data_import(test_path)\n",
    "# train_data, train_labels = data_import(train_path)\n",
    "# val_data, val_labels = data_import(val_path)\n",
    "\n",
    "# with open('test_data', mode='wb') as f:\n",
    "#     pickle.dump(test_data, f)\n",
    "# with open('train_data', mode='wb') as f:\n",
    "#     pickle.dump(train_data, f)\n",
    "# with open('val_data', mode='wb') as f:\n",
    "#     pickle.dump(val_data, f)\n",
    "\n",
    "# with open('test_labels', mode='wb') as f:\n",
    "#     pickle.dump(test_labels, f)\n",
    "# with open('train_labels', mode='wb') as f:\n",
    "#     pickle.dump(train_labels, f)\n",
    "# with open('val_labels', mode='wb') as f:\n",
    "#     pickle.dump(val_labels, f)\n",
    "\n",
    "with open('test_data', mode='rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open('train_data', mode='rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('val_data', mode='rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "\n",
    "with open('test_labels', mode='rb') as f:\n",
    "    test_labels = pickle.load(f)\n",
    "with open('train_labels', mode='rb') as f:\n",
    "    train_labels = pickle.load(f)\n",
    "with open('val_labels', mode='rb') as f:\n",
    "    val_labels = pickle.load(f)\n",
    "\n",
    "print('Summary of data')\n",
    "print(f'No. of train images: {len(train_data)}')\n",
    "print(f'No. of test images: {len(test_data)}')\n",
    "print(f'No. of val images: {len(val_data)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FCNN_3layer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Flatten)       (None, 784)               0         \n",
      "                                                                 \n",
      " Hidden_layer_1 (Dense)      (None, 250)               196250    \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 400)               100400    \n",
      "                                                                 \n",
      " Hidden_layer_3 (Dense)      (None, 100)               40100     \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337,760\n",
      "Trainable params: 337,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = keras.initializers.RandomUniform(minval=-1, maxval=1, seed=6)\n",
    "# Three layer FCNN\n",
    "model_3 = keras.Sequential([\n",
    "    Flatten(input_shape=(28,28), name='Input_layer'), # image data as input\n",
    "    Dense(250, activation='sigmoid', kernel_initializer=initializer, bias_initializer=keras.initializers.Zeros(), name='Hidden_layer_1'),\n",
    "    Dense(250, activation='sigmoid', kernel_initializer=initializer, bias_initializer=keras.initializers.Zeros(), name='Hidden_layer_2'),\n",
    "    Dense(100, activation='sigmoid', kernel_initializer=initializer, bias_initializer=keras.initializers.Zeros(), name='Hidden_layer_3'),\n",
    "    Dense(10, activation='softmax', kernel_initializer=initializer, bias_initializer=keras.initializers.Zeros(), name='Output')\n",
    "], name='FCNN_3layer')\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-4, patience=3, verbose=1)\n",
    "# modelCheckpointsSGD_momentum = keras.callbacks.ModelCheckpoint(filepath='./modelCheckpoints/SGD_momentum/model.{epoch:02d}-{loss:.2f}.h5', verbose=0)\n",
    "sgd_moment_optimizer = keras.optimizers.Adagrad(learning_rate=0.001, epsilon=1e-10, name='AdaGrad')\n",
    "model_3.compile(optimizer=sgd_moment_optimizer,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "11385/11385 [==============================] - 11s 921us/step - loss: 1.3186 - accuracy: 0.5357 - val_loss: 0.8819 - val_accuracy: 0.6701\n",
      "Epoch 2/100000\n",
      "11385/11385 [==============================] - 10s 919us/step - loss: 0.7577 - accuracy: 0.7325 - val_loss: 0.7048 - val_accuracy: 0.7452\n",
      "Epoch 3/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.6225 - accuracy: 0.7845 - val_loss: 0.6169 - val_accuracy: 0.7845\n",
      "Epoch 4/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.5448 - accuracy: 0.8162 - val_loss: 0.5590 - val_accuracy: 0.8074\n",
      "Epoch 5/100000\n",
      "11385/11385 [==============================] - 10s 914us/step - loss: 0.4926 - accuracy: 0.8366 - val_loss: 0.5200 - val_accuracy: 0.8221\n",
      "Epoch 6/100000\n",
      "11385/11385 [==============================] - 10s 914us/step - loss: 0.4540 - accuracy: 0.8530 - val_loss: 0.4906 - val_accuracy: 0.8306\n",
      "Epoch 7/100000\n",
      "11385/11385 [==============================] - 10s 916us/step - loss: 0.4252 - accuracy: 0.8632 - val_loss: 0.4663 - val_accuracy: 0.8408\n",
      "Epoch 8/100000\n",
      "11385/11385 [==============================] - 10s 906us/step - loss: 0.4019 - accuracy: 0.8717 - val_loss: 0.4468 - val_accuracy: 0.8485\n",
      "Epoch 9/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.3823 - accuracy: 0.8789 - val_loss: 0.4294 - val_accuracy: 0.8556\n",
      "Epoch 10/100000\n",
      "11385/11385 [==============================] - 10s 914us/step - loss: 0.3660 - accuracy: 0.8833 - val_loss: 0.4149 - val_accuracy: 0.8606\n",
      "Epoch 11/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.3515 - accuracy: 0.8877 - val_loss: 0.4023 - val_accuracy: 0.8656\n",
      "Epoch 12/100000\n",
      "11385/11385 [==============================] - 11s 923us/step - loss: 0.3389 - accuracy: 0.8922 - val_loss: 0.3922 - val_accuracy: 0.8688\n",
      "Epoch 13/100000\n",
      "11385/11385 [==============================] - 10s 920us/step - loss: 0.3281 - accuracy: 0.8972 - val_loss: 0.3819 - val_accuracy: 0.8722\n",
      "Epoch 14/100000\n",
      "11385/11385 [==============================] - 10s 918us/step - loss: 0.3181 - accuracy: 0.8993 - val_loss: 0.3731 - val_accuracy: 0.8756\n",
      "Epoch 15/100000\n",
      "11385/11385 [==============================] - 10s 916us/step - loss: 0.3092 - accuracy: 0.9027 - val_loss: 0.3650 - val_accuracy: 0.8801\n",
      "Epoch 16/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.3008 - accuracy: 0.9060 - val_loss: 0.3582 - val_accuracy: 0.8817\n",
      "Epoch 17/100000\n",
      "11385/11385 [==============================] - 10s 916us/step - loss: 0.2931 - accuracy: 0.9088 - val_loss: 0.3517 - val_accuracy: 0.8833\n",
      "Epoch 18/100000\n",
      "11385/11385 [==============================] - 10s 916us/step - loss: 0.2862 - accuracy: 0.9121 - val_loss: 0.3452 - val_accuracy: 0.8859\n",
      "Epoch 19/100000\n",
      "11385/11385 [==============================] - 10s 918us/step - loss: 0.2798 - accuracy: 0.9140 - val_loss: 0.3394 - val_accuracy: 0.8877\n",
      "Epoch 20/100000\n",
      "11385/11385 [==============================] - 10s 918us/step - loss: 0.2739 - accuracy: 0.9164 - val_loss: 0.3342 - val_accuracy: 0.8885\n",
      "Epoch 21/100000\n",
      "11385/11385 [==============================] - 10s 922us/step - loss: 0.2685 - accuracy: 0.9187 - val_loss: 0.3290 - val_accuracy: 0.8904\n",
      "Epoch 22/100000\n",
      "11385/11385 [==============================] - 10s 920us/step - loss: 0.2633 - accuracy: 0.9204 - val_loss: 0.3246 - val_accuracy: 0.8930\n",
      "Epoch 23/100000\n",
      "11385/11385 [==============================] - 10s 921us/step - loss: 0.2584 - accuracy: 0.9215 - val_loss: 0.3198 - val_accuracy: 0.8943\n",
      "Epoch 24/100000\n",
      "11385/11385 [==============================] - 10s 920us/step - loss: 0.2540 - accuracy: 0.9231 - val_loss: 0.3156 - val_accuracy: 0.8949\n",
      "Epoch 25/100000\n",
      "11385/11385 [==============================] - 10s 918us/step - loss: 0.2497 - accuracy: 0.9253 - val_loss: 0.3112 - val_accuracy: 0.8959\n",
      "Epoch 26/100000\n",
      "11385/11385 [==============================] - 10s 917us/step - loss: 0.2458 - accuracy: 0.9260 - val_loss: 0.3076 - val_accuracy: 0.8980\n",
      "Epoch 27/100000\n",
      "11385/11385 [==============================] - 10s 919us/step - loss: 0.2418 - accuracy: 0.9273 - val_loss: 0.3043 - val_accuracy: 0.8988\n",
      "Epoch 28/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.2382 - accuracy: 0.9286 - val_loss: 0.3013 - val_accuracy: 0.9017\n",
      "Epoch 29/100000\n",
      "11385/11385 [==============================] - 10s 914us/step - loss: 0.2347 - accuracy: 0.9296 - val_loss: 0.2981 - val_accuracy: 0.9020\n",
      "Epoch 30/100000\n",
      "11385/11385 [==============================] - 10s 917us/step - loss: 0.2314 - accuracy: 0.9302 - val_loss: 0.2952 - val_accuracy: 0.9033\n",
      "Epoch 31/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.2283 - accuracy: 0.9318 - val_loss: 0.2924 - val_accuracy: 0.9036\n",
      "Epoch 32/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.2252 - accuracy: 0.9322 - val_loss: 0.2897 - val_accuracy: 0.9049\n",
      "Epoch 33/100000\n",
      "11385/11385 [==============================] - 10s 918us/step - loss: 0.2223 - accuracy: 0.9331 - val_loss: 0.2870 - val_accuracy: 0.9062\n",
      "Epoch 34/100000\n",
      "11385/11385 [==============================] - 11s 935us/step - loss: 0.2196 - accuracy: 0.9337 - val_loss: 0.2845 - val_accuracy: 0.9062\n",
      "Epoch 35/100000\n",
      "11385/11385 [==============================] - 11s 927us/step - loss: 0.2169 - accuracy: 0.9346 - val_loss: 0.2821 - val_accuracy: 0.9072\n",
      "Epoch 36/100000\n",
      "11385/11385 [==============================] - 11s 944us/step - loss: 0.2143 - accuracy: 0.9356 - val_loss: 0.2801 - val_accuracy: 0.9099\n",
      "Epoch 37/100000\n",
      "11385/11385 [==============================] - 10s 889us/step - loss: 0.2119 - accuracy: 0.9365 - val_loss: 0.2779 - val_accuracy: 0.9101\n",
      "Epoch 38/100000\n",
      "11385/11385 [==============================] - 10s 889us/step - loss: 0.2095 - accuracy: 0.9375 - val_loss: 0.2759 - val_accuracy: 0.9109\n",
      "Epoch 39/100000\n",
      "11385/11385 [==============================] - 10s 887us/step - loss: 0.2072 - accuracy: 0.9383 - val_loss: 0.2737 - val_accuracy: 0.9109\n",
      "Epoch 40/100000\n",
      "11385/11385 [==============================] - 10s 890us/step - loss: 0.2050 - accuracy: 0.9390 - val_loss: 0.2718 - val_accuracy: 0.9115\n",
      "Epoch 41/100000\n",
      "11385/11385 [==============================] - 10s 888us/step - loss: 0.2029 - accuracy: 0.9394 - val_loss: 0.2702 - val_accuracy: 0.9128\n",
      "Epoch 42/100000\n",
      "11385/11385 [==============================] - 10s 893us/step - loss: 0.2007 - accuracy: 0.9405 - val_loss: 0.2682 - val_accuracy: 0.9130\n",
      "Epoch 43/100000\n",
      "11385/11385 [==============================] - 10s 893us/step - loss: 0.1988 - accuracy: 0.9410 - val_loss: 0.2664 - val_accuracy: 0.9136\n",
      "Epoch 44/100000\n",
      "11385/11385 [==============================] - 10s 909us/step - loss: 0.1968 - accuracy: 0.9414 - val_loss: 0.2648 - val_accuracy: 0.9144\n",
      "Epoch 45/100000\n",
      "11385/11385 [==============================] - 10s 913us/step - loss: 0.1949 - accuracy: 0.9420 - val_loss: 0.2631 - val_accuracy: 0.9154\n",
      "Epoch 46/100000\n",
      "11385/11385 [==============================] - 11s 929us/step - loss: 0.1932 - accuracy: 0.9423 - val_loss: 0.2616 - val_accuracy: 0.9149\n",
      "Epoch 47/100000\n",
      "11385/11385 [==============================] - 11s 928us/step - loss: 0.1914 - accuracy: 0.9432 - val_loss: 0.2598 - val_accuracy: 0.9152\n",
      "Epoch 48/100000\n",
      "11385/11385 [==============================] - 11s 931us/step - loss: 0.1897 - accuracy: 0.9437 - val_loss: 0.2585 - val_accuracy: 0.9157\n",
      "Epoch 49/100000\n",
      "11385/11385 [==============================] - 11s 933us/step - loss: 0.1880 - accuracy: 0.9443 - val_loss: 0.2572 - val_accuracy: 0.9159\n",
      "Epoch 50/100000\n",
      "11385/11385 [==============================] - 12s 1ms/step - loss: 0.1865 - accuracy: 0.9449 - val_loss: 0.2558 - val_accuracy: 0.9157\n",
      "Epoch 51/100000\n",
      "11385/11385 [==============================] - 11s 928us/step - loss: 0.1849 - accuracy: 0.9453 - val_loss: 0.2545 - val_accuracy: 0.9165\n",
      "Epoch 52/100000\n",
      "11385/11385 [==============================] - 11s 953us/step - loss: 0.1833 - accuracy: 0.9461 - val_loss: 0.2532 - val_accuracy: 0.9167\n",
      "Epoch 53/100000\n",
      "11385/11385 [==============================] - 11s 964us/step - loss: 0.1819 - accuracy: 0.9465 - val_loss: 0.2518 - val_accuracy: 0.9173\n",
      "Epoch 54/100000\n",
      "11385/11385 [==============================] - 10s 921us/step - loss: 0.1804 - accuracy: 0.9468 - val_loss: 0.2507 - val_accuracy: 0.9188\n",
      "Epoch 55/100000\n",
      "11385/11385 [==============================] - 11s 924us/step - loss: 0.1790 - accuracy: 0.9473 - val_loss: 0.2494 - val_accuracy: 0.9188\n",
      "Epoch 56/100000\n",
      "11385/11385 [==============================] - 70s 6ms/step - loss: 0.1776 - accuracy: 0.9477 - val_loss: 0.2483 - val_accuracy: 0.9204\n",
      "Epoch 57/100000\n",
      "11385/11385 [==============================] - 10s 921us/step - loss: 0.1763 - accuracy: 0.9480 - val_loss: 0.2471 - val_accuracy: 0.9207\n",
      "Epoch 58/100000\n",
      "11385/11385 [==============================] - 11s 930us/step - loss: 0.1750 - accuracy: 0.9491 - val_loss: 0.2458 - val_accuracy: 0.9207\n",
      "Epoch 59/100000\n",
      "11385/11385 [==============================] - 11s 925us/step - loss: 0.1737 - accuracy: 0.9491 - val_loss: 0.2448 - val_accuracy: 0.9212\n",
      "Epoch 60/100000\n",
      "11385/11385 [==============================] - 11s 923us/step - loss: 0.1725 - accuracy: 0.9494 - val_loss: 0.2437 - val_accuracy: 0.9217\n",
      "Epoch 61/100000\n",
      "11385/11385 [==============================] - 10s 921us/step - loss: 0.1712 - accuracy: 0.9499 - val_loss: 0.2425 - val_accuracy: 0.9215\n",
      "Epoch 62/100000\n",
      "11385/11385 [==============================] - 11s 929us/step - loss: 0.1701 - accuracy: 0.9502 - val_loss: 0.2415 - val_accuracy: 0.9220\n",
      "Epoch 63/100000\n",
      "11385/11385 [==============================] - 10s 921us/step - loss: 0.1689 - accuracy: 0.9505 - val_loss: 0.2406 - val_accuracy: 0.9223\n",
      "Epoch 64/100000\n",
      "11385/11385 [==============================] - 10s 915us/step - loss: 0.1678 - accuracy: 0.9512 - val_loss: 0.2395 - val_accuracy: 0.9225\n",
      "Epoch 65/100000\n",
      "11385/11385 [==============================] - 11s 929us/step - loss: 0.1666 - accuracy: 0.9507 - val_loss: 0.2387 - val_accuracy: 0.9228\n",
      "Epoch 66/100000\n",
      "11357/11385 [============================>.] - ETA: 0s - loss: 0.1658 - accuracy: 0.9515"
     ]
    }
   ],
   "source": [
    "history = model_3.fit(x=train_data, y=train_labels, batch_size=1, epochs=100_000,\n",
    "                    callbacks=[earlystopping],\n",
    "                    verbose=1, shuffle=True,\n",
    "                    validation_split=0.0, validation_data=(val_data, val_labels), validation_batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"AdaGrad\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model_3.predict(test_data, verbose=0)\n",
    "pred_labels = np.argmax(pred_labels, axis=1)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(test_labels, pred_labels, num_classes=10)\n",
    "print('(AdaGrad)Confusion matrix on test data:\\n')\n",
    "print(confusion_matrix.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
