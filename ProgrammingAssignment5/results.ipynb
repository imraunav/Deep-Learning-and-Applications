{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.math import confusion_matrix\n",
    "from helper import data_import, relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='./Group_10/train'\n",
    "test_path='./Group_10/test'\n",
    "val_path='./Group_10/val'\n",
    "\n",
    "# All of these are lists. Images are not of same shape, hence can't have np.array()\n",
    "x_train, y_train = data_import(train_path)\n",
    "x_test, y_test = data_import(test_path)\n",
    "x_val, y_val = data_import(val_path)\n",
    "\n",
    "y_train = relabel(y_train)\n",
    "y_test = relabel(y_test)\n",
    "y_val = relabel(y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architechture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n",
      "Model: \"Architecture1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 54, 54, 8)         2912      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 16)        3216      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,186,549\n",
      "Trainable params: 1,186,549\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:31.720245: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-27 11:03:31.720340: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./models/architecture1.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and accuracy for architechture 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:31.939227: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-04-27 11:03:32.049788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0005\n",
      "Accuracy: 1.0000\n",
      "[[50  0  0  0  0]\n",
      " [ 0 50  0  0  0]\n",
      " [ 0  0 50  0  0]\n",
      " [ 0  0  0 50  0]\n",
      " [ 0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loss and accuracy for architechture 1:\")\n",
    "loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "y_pdfs = model(x_train)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_train, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss and accuracy for architechture 1:\n",
      "Loss 1.0656\n",
      "Accuracy: 0.8000\n",
      "[[10  0  0  0  0]\n",
      " [ 0  7  1  0  2]\n",
      " [ 1  1  7  1  0]\n",
      " [ 1  1  2  6  0]\n",
      " [ 0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss and accuracy for architechture 1:\")\n",
    "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "y_pdfs = model(x_val)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_val, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss and accuracy for architechture 1:\n",
      "Loss 0.9637\n",
      "Accuracy: 0.7900\n",
      "Confusion matrix:\n",
      "[[17  2  0  0  1]\n",
      " [ 0 17  0  1  2]\n",
      " [ 1  2 16  1  0]\n",
      " [ 0  1  2 15  2]\n",
      " [ 0  6  0  0 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss and accuracy for architechture 1:\")\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pdfs = model(x_test)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architechture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Architecture2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 54, 54, 8)         2912      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 16)        3216      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16928)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2166912   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,178,325\n",
      "Trainable params: 2,178,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./models/architecture2.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and accuracy for architechture 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:32.801566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0005\n",
      "Accuracy: 1.0000\n",
      "[[50  0  0  0  0]\n",
      " [ 0 50  0  0  0]\n",
      " [ 0  0 50  0  0]\n",
      " [ 0  0  0 50  0]\n",
      " [ 0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loss and accuracy for architechture 2:\")\n",
    "loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "y_pdfs = model(x_train)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_train, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss and accuracy for architechture 2:\n",
      "Loss 0.9502\n",
      "Accuracy: 0.8400\n",
      "[[10  0  0  0  0]\n",
      " [ 0  7  1  0  2]\n",
      " [ 0  0  7  1  2]\n",
      " [ 0  1  0  9  0]\n",
      " [ 0  0  1  0  9]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss and accuracy for architechture 2:\")\n",
    "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "y_pdfs = model(x_val)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_val, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss and accuracy for architechture 2:\n",
      "Loss 1.1578\n",
      "Accuracy: 0.7600\n",
      "Confusion matrix:\n",
      "[[17  2  0  0  1]\n",
      " [ 0 15  0  1  4]\n",
      " [ 1  2 16  1  0]\n",
      " [ 1  1  2 14  2]\n",
      " [ 0  5  0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss and accuracy for architechture 2:\")\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pdfs = model(x_test)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred).numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architechture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Architecture3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 54, 54, 8)         2912      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 16)        3216      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 46, 46, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 22, 22, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,994,965\n",
      "Trainable params: 3,994,965\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"./models/architecture3.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss and accuracy for architechture 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 11:03:33.606593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.0006\n",
      "Accuracy: 1.0000\n",
      "[[50  0  0  0  0]\n",
      " [ 0 50  0  0  0]\n",
      " [ 0  0 50  0  0]\n",
      " [ 0  0  0 50  0]\n",
      " [ 0  0  0  0 50]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loss and accuracy for architechture 3:\")\n",
    "loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "y_pdfs = model(x_train)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_train, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss and accuracy for architechture 3:\n",
      "Loss 0.9665\n",
      "Accuracy: 0.8200\n",
      "[[10  0  0  0  0]\n",
      " [ 0  8  1  0  1]\n",
      " [ 1  0  7  1  1]\n",
      " [ 0  1  1  8  0]\n",
      " [ 0  2  0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss and accuracy for architechture 3:\")\n",
    "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "y_pdfs = model(x_val)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(confusion_matrix(y_val, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss and accuracy for architechture 3:\n",
      "Loss 1.2955\n",
      "Accuracy: 0.7600\n",
      "Confusion matrix:\n",
      "[[17  2  0  0  1]\n",
      " [ 0 16  1  1  2]\n",
      " [ 1  0 17  1  1]\n",
      " [ 0  1  3 15  1]\n",
      " [ 1  7  0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss and accuracy for architechture 3:\")\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pdfs = model(x_test)\n",
    "y_pred = tf.argmax(y_pdfs, axis=1)\n",
    "print(f\"Loss {loss:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
